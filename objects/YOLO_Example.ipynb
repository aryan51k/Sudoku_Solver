{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:33:44.138409Z",
     "start_time": "2017-11-26T12:33:41.531465Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "from utils import BoundBox, normalize, bbox_iou, interval_overlap, draw_boxes, decode_netout, sigmoid, softmax\n",
    "from BatchGenerator import BatchGenerator\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjustable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/Owner/Desktop/Folder/')\n",
    "\n",
    "architecture       = 'MobileNet'\n",
    "input_size         = 224\n",
    "anchors            = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "max_box_per_image  = 5\n",
    "labels_list        = ['target']\n",
    "\n",
    "train_image_folder = 'train/image/'\n",
    "train_annot_folder = 'train/annot/'\n",
    "pretrained_weights_file = 'mobilenet_raccoon.h5'\n",
    "backend_weights_file  = \"mobilenet_backend.h5\"\n",
    "batch_size         = 16\n",
    "nb_epoch           = 100\n",
    "object_scale       = 5.0\n",
    "no_object_scale    = 1.0\n",
    "coord_scale        = 1.0\n",
    "class_scale        = 1.0\n",
    "debug_flag         = True\n",
    "\n",
    "valid_image_folder = 'verify/image/'\n",
    "valid_annot_folder = 'verify/annot/'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T14:07:49.271978Z",
     "start_time": "2017-11-22T14:07:49.268999Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    mask_shape = tf.shape(y_true)[:4]\n",
    "\n",
    "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(grid_w), [grid_h]), (1, grid_h, grid_w, 1, 1)))\n",
    "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
    "\n",
    "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [batch_size, 1, 1, 5, 1])\n",
    "\n",
    "    coord_mask = tf.zeros(mask_shape)\n",
    "    conf_mask  = tf.zeros(mask_shape)\n",
    "    class_mask = tf.zeros(mask_shape)\n",
    "\n",
    "    seen = tf.Variable(0.)\n",
    "    total_recall = tf.Variable(0.)\n",
    "\n",
    "    ### adjust x and y      \n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "\n",
    "    ### adjust w and h\n",
    "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(anchors, [1,1,1,nb_box,2])\n",
    "\n",
    "    ### adjust confidence\n",
    "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
    "\n",
    "    ### adjust class probabilities\n",
    "    pred_box_class = y_pred[..., 5:]\n",
    "\n",
    "    ### adjust x and y\n",
    "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
    "\n",
    "    ### adjust w and h\n",
    "    true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
    "\n",
    "    ### adjust confidence\n",
    "    true_wh_half = true_box_wh / 2.\n",
    "    true_mins    = true_box_xy - true_wh_half\n",
    "    true_maxes   = true_box_xy + true_wh_half\n",
    "\n",
    "    pred_wh_half = pred_box_wh / 2.\n",
    "    pred_mins    = pred_box_xy - pred_wh_half\n",
    "    pred_maxes   = pred_box_xy + pred_wh_half       \n",
    "\n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "\n",
    "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "    true_box_conf = iou_scores * y_true[..., 4]\n",
    "\n",
    "    ### adjust class probabilities\n",
    "    true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
    "\n",
    "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
    "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * coord_scale\n",
    "\n",
    "    ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
    "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "    true_xy = true_boxes[..., 0:2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "\n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins    = true_xy - true_wh_half\n",
    "    true_maxes   = true_xy + true_wh_half\n",
    "\n",
    "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
    "\n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins    = pred_xy - pred_wh_half\n",
    "    pred_maxes   = pred_xy + pred_wh_half    \n",
    "\n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "\n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "    best_ious = tf.reduce_max(iou_scores, axis=4)\n",
    "    conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * no_object_scale\n",
    "\n",
    "    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
    "    conf_mask = conf_mask + y_true[..., 4] * object_scale\n",
    "\n",
    "    ### class mask: simply the position of the ground truth boxes (the predictors)\n",
    "    class_mask = y_true[..., 4] * tf.gather(class_wt, true_box_class) * class_scale       \n",
    "\n",
    "    \"\"\"\n",
    "    Warm-up training\n",
    "    \"\"\"\n",
    "    no_boxes_mask = tf.to_float(coord_mask < coord_scale/2.)\n",
    "    seen = tf.assign_add(seen, 1.)\n",
    "\n",
    "    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, warmup_bs), \n",
    "                          lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \n",
    "                                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(anchors, [1,1,1,nb_box,2]) * no_boxes_mask, \n",
    "                                   tf.ones_like(coord_mask)],\n",
    "                          lambda: [true_box_xy, \n",
    "                                   true_box_wh,\n",
    "                                   coord_mask])\n",
    "\n",
    "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
    "    nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
    "    nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
    "\n",
    "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
    "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
    "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
    "\n",
    "    loss = loss_xy + loss_wh + loss_conf + loss_class\n",
    "\n",
    "    if debug_flag:\n",
    "        nb_true_box = tf.reduce_sum(y_true[..., 4])\n",
    "        nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\n",
    "\n",
    "        current_recall = nb_pred_box/(nb_true_box + 1e-6)\n",
    "        total_recall = tf.assign_add(total_recall, current_recall) \n",
    "\n",
    "        loss = tf.Print(loss, [tf.zeros((1))], message='Dummy Line \\t', summarize=1000)\n",
    "        loss = tf.Print(loss, [loss_xy], message='Loss XY \\t', summarize=1000)\n",
    "        loss = tf.Print(loss, [loss_wh], message='Loss WH \\t', summarize=1000)\n",
    "        loss = tf.Print(loss, [loss_conf], message='Loss Conf \\t', summarize=1000)\n",
    "        loss = tf.Print(loss, [loss_class], message='Loss Class \\t', summarize=1000)\n",
    "        loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\n",
    "        loss = tf.Print(loss, [current_recall], message='Current Recall \\t', summarize=1000)\n",
    "        loss = tf.Print(loss, [total_recall/seen], message='Average Recall \\t', summarize=1000)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_class   = len(list(labels_list))\n",
    "nb_box   = max_box_per_image\n",
    "class_wt = np.ones(nb_class, dtype='float32')\n",
    "\n",
    "warmup_epochs = 0\n",
    "warmup_bs  = 0\n",
    "\n",
    "true_boxes = Input(shape=(1, 1, 1, max_box_per_image , 4))  \n",
    "input_image = Input(shape=(input_size, input_size, 3))\n",
    "\n",
    "# MobileNet\n",
    "mobilenet = MobileNet(input_shape=(input_size,input_size,3), include_top=False)\n",
    "mobilenet.load_weights(backend_weights_file)\n",
    "x = mobilenet(input_image)\n",
    "feature_extractor = Model(input_image, x)  \n",
    "print(feature_extractor.get_output_shape_at(-1)[1:3])    \n",
    "grid_h, grid_w = feature_extractor.get_output_shape_at(-1)[1:3]        \n",
    "\n",
    "# object detection layer\n",
    "output = Conv2D(nb_box * (4 + 1 + nb_class), \n",
    "                (1,1), strides=(1,1), \n",
    "                padding='same', \n",
    "                name='conv_23', \n",
    "                kernel_initializer='lecun_normal')(x)\n",
    "output = Reshape((grid_h, grid_w, nb_box, 4 + 1 + nb_class))(output)\n",
    "output = Lambda(lambda args: args[0])([output, true_boxes])\n",
    "model = Model([input_image, true_boxes], output)\n",
    "\n",
    "optimizer = Adam(lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n",
    "#optimizer = RMSprop(lr=1e-6, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss=custom_loss, optimizer=optimizer)\n",
    "\n",
    "# print a summary of the whole model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  reset weights of the detection layer\n",
    "layer = model.layers[-4] # the last convolutional layer\n",
    "weights = layer.get_weights()\n",
    "new_kernel = np.random.normal(size=weights[0].shape)/(grid_h*grid_w)\n",
    "new_bias   = np.random.normal(size=weights[1].shape)/(grid_h*grid_w)\n",
    "layer.set_weights([new_kernel, new_bias])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Images and Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotation(ann_dir, img_dir, labels_list=[]):\n",
    "    all_imgs = []\n",
    "\n",
    "    images = os.listdir(img_dir)\n",
    "    annots = os.listdir(ann_dir)\n",
    "\n",
    "    if len(images) == len(annots):\n",
    "        print('Number of Images == Number of Annotations = GOOD!')\n",
    "\n",
    "    for n in range(0,len(images)):\n",
    "        img = {'object':[]}\n",
    "        img['filename'] = img_dir + images[n]\n",
    "        img['width'] = int(128)\n",
    "        img['height'] = int(128)\n",
    "\n",
    "        with open(ann_dir + annots[n], 'r') as infile:\n",
    "            lines = infile.readlines()\n",
    "\n",
    "            #line 1\n",
    "            n_bbox = int(lines[0])\n",
    "\n",
    "            for bbox_n in range(0,n_bbox):\n",
    "                line_data = lines[1+bbox_n]\n",
    "                x_min,y_min,x_max,y_max = line_data.split(' ')\n",
    "\n",
    "                obj = {}\n",
    "                obj['name'] = 'target'\n",
    "                obj['xmin'] = int(x_min)\n",
    "                obj['ymin'] = int(y_min)\n",
    "                obj['xmax'] = int(x_max)\n",
    "                obj['ymax'] = int(y_max)\n",
    "                img['object'] += [obj]\n",
    "\n",
    "        all_imgs += [img]\n",
    "\n",
    "    return all_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = parse_annotation(train_annot_folder, \n",
    "                                            train_image_folder, \n",
    "                                            labels_list)\n",
    "\n",
    "valid_imgs = parse_annotation(valid_annot_folder, \n",
    "                                                valid_image_folder, \n",
    "                                                labels_list)\n",
    "\n",
    "generator_config = {\n",
    "    'IMAGE_H'         : input_size, \n",
    "    'IMAGE_W'         : input_size,\n",
    "    'GRID_H'          : grid_h,  \n",
    "    'GRID_W'          : grid_w,\n",
    "    'BOX'             : max_box_per_image,\n",
    "    'LABELS'          : labels_list,\n",
    "    'CLASS'           : len(labels_list),\n",
    "    'ANCHORS'         : anchors,\n",
    "    'BATCH_SIZE'      : batch_size,\n",
    "    'TRUE_BOX_BUFFER' : 5,\n",
    "}\n",
    "    \n",
    "train_batch = BatchGenerator(train_imgs, \n",
    "                             generator_config, \n",
    "                             norm=normalize)\n",
    "valid_batch = BatchGenerator(valid_imgs, \n",
    "                             generator_config, \n",
    "                             norm=normalize,\n",
    "                             jitter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(pretrained_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_target_detector.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T20:38:54.037Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "#  Train CNN\n",
    "###############################\n",
    "\n",
    "checkpoint = ModelCheckpoint('best_target_detector.h5', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='auto', \n",
    "                             period=1)\n",
    "\n",
    "model.fit_generator(generator        = train_batch, \n",
    "                    steps_per_epoch  = math.ceil(1000/batch_size),\n",
    "                    epochs           = nb_epoch, \n",
    "                    verbose          = 2,\n",
    "                    validation_data  = valid_batch,\n",
    "                    validation_steps = math.ceil(250/batch_size),\n",
    "                    callbacks        = [checkpoint], \n",
    "                    max_queue_size   = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T14:07:52.566171Z",
     "start_time": "2017-11-22T14:07:50.655879Z"
    }
   },
   "outputs": [],
   "source": [
    "obj_threshold       = 0.0\n",
    "nms_threshold       = 0.0\n",
    "\n",
    "#model.load_weights('mobilenet_raccoon.h5')\n",
    "#model.load_weights('best_raccoon_detector.h5')\n",
    "model.load_weights('best_target_detector.h5')\n",
    "\n",
    "\n",
    "image = cv2.imread('verify/image/Detection_942_10_Chip.JPEG')\n",
    "\n",
    "image = cv2.resize(image, (input_size, input_size))\n",
    "norm_image = normalize(image)\n",
    "\n",
    "input_image = norm_image[:,:,::-1]\n",
    "input_image = np.expand_dims(input_image, 0)\n",
    "dummy_array = np.zeros((1,1,1,1,max_box_per_image,4))\n",
    "\n",
    "netout = model.predict([input_image, dummy_array])[0]\n",
    "boxes = decode_netout(netout, \n",
    "                      obj_threshold=obj_threshold,\n",
    "                      nms_threshold=nms_threshold,\n",
    "                      anchors=anchors, \n",
    "                      nb_class=len(labels_list))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "image = draw_boxes(image, boxes, labels_list)\n",
    "print(len(boxes), 'boxes are found')\n",
    "plt.imshow(image[:,:,::-1]); plt.show()\n",
    "cv2.imwrite('raccoon' + '_detected' + '.jpg', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-06T13:39:09.640646Z",
     "start_time": "2017-10-06T13:31:44.627609Z"
    }
   },
   "outputs": [],
   "source": [
    "# untested, not sure if working\n",
    "\n",
    "obj_threshold       = 0.0\n",
    "nms_threshold       = 0.0\n",
    "\n",
    "model.load_weights(\"mobilenet_raccoon.h5\")\n",
    "\n",
    "dummy_array = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4))\n",
    "\n",
    "video_inp = '../basic-yolo-keras/images/phnom_penh.mp4'\n",
    "video_out = '../basic-yolo-keras/images/phnom_penh_bbox.mp4'\n",
    "\n",
    "video_reader = cv2.VideoCapture(video_inp)\n",
    "\n",
    "nb_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_h = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_w = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "video_writer = cv2.VideoWriter(video_out,\n",
    "                               cv2.VideoWriter_fourcc(*'XVID'), \n",
    "                               50.0, \n",
    "                               (frame_w, frame_h))\n",
    "\n",
    "for i in tqdm(range(nb_frames)):\n",
    "    ret, image = video_reader.read()\n",
    "    \n",
    "    input_image = cv2.resize(image, (416, 416))\n",
    "    input_image = input_image / 255.\n",
    "    input_image = input_image[:,:,::-1]\n",
    "    input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "    netout = model.predict([input_image, dummy_array])\n",
    "\n",
    "    boxes = decode_netout(netout[0], \n",
    "                          obj_threshold=0.3,\n",
    "                          nms_threshold=NMS_THRESHOLD,\n",
    "                          anchors=ANCHORS, \n",
    "                          nb_class=CLASS)\n",
    "    image = draw_boxes(image, boxes, labels=labels_list)\n",
    "\n",
    "    video_writer.write(np.uint8(image))\n",
    "    \n",
    "video_reader.release()\n",
    "video_writer.release()  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {
    "height": "381px",
    "width": "251px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "758px",
    "left": "0px",
    "right": "1096px",
    "top": "73px",
    "width": "253px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
